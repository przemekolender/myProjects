{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-missile",
   "metadata": {},
   "source": [
    "# Wczytanie Danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "data_lab = pd.read_csv('AllBooks_baseline_DTM_Labelled.csv')\n",
    "\n",
    "cols = df.columns\n",
    "texts = [''] * len(df)\n",
    "for i in range(len(df)):\n",
    "    t = texts[i]\n",
    "    tmp_num = np.array(df.iloc[i])\n",
    "    for j in range(len(tmp_num)):\n",
    "        w = int(tmp_num[j])\n",
    "        for k in range(w): t = t + ' ' + cols[j]\n",
    "    texts[i] = str(t)\n",
    "#    print(texts[i])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=2, use_idf=True, stop_words='english', token_pattern=r\"\\b[^\\d\\W]+\\b\")\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "df_tfidf = pd.DataFrame(tfidf.toarray(), columns=list(tfidf_feature_names))\n",
    "\n",
    "#ramka danych ze statystykami tesktów\n",
    "stats = pd.read_csv('stats_df.csv')\n",
    "stats = stats.drop(['Unnamed: 0', 'index', 'text'], axis = 1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(stats)\n",
    "stat_scale = scaler.transform(stats)\n",
    "\n",
    "stats_scale = pd.DataFrame(stat_scale, columns = stats.columns)\n",
    "\n",
    "X = pd.merge(stats_scale.reset_index(), df_tfidf.reset_index(), on = 'index').drop('index', axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv('AllBooks_baseline_DTM_Labelled.csv')[['Unnamed: 0']]\n",
    "Y['label'] = Y['Unnamed: 0'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "def add_religion(label):\n",
    "  if label == \"Buddhism\": return \"Buddhism\"\n",
    "  elif label == \"TaoTeChing\": return \"Taoism\"\n",
    "  elif (label == \"Upanishad\") | (label ==\"YogaSutra\"): return \"Hindusim\"\n",
    "  else: return \"Old testament\"\n",
    "\n",
    "    \n",
    "Y['rel'] = Y['label'].apply(lambda x : add_religion(x))\n",
    "Y = Y.drop('Unnamed: 0', axis = 1)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-principle",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_)+1), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.xlim(0, 100)\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-subscriber",
   "metadata": {},
   "source": [
    "Dla 3 komponentów mamy wyjaśnione 85% wariancji, 90% jest wyjaśnione przez 45 komponentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca45 = PCA(n_components=45).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 8])\n",
    "tSNE = TSNE(random_state=0, verbose=1)\n",
    "X_tsne = tSNE.fit_transform(X_pca45)\n",
    "X_tsne = pd.DataFrame({'x': X_tsne[:, 0], 'y': X_tsne[:, 1], 'label': Y['label'], 'rel' : Y['rel']})\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=[18, 6])\n",
    "sns.scatterplot(data=X_tsne, x='x', y='y', hue='label', ax = ax1)\n",
    "sns.scatterplot(data=X_tsne, x='x', y='y', hue='rel', ax = ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, rand_score, adjusted_mutual_info_score, mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeansClustering(data, reduction, actual_labels):\n",
    "    results = pd.DataFrame(columns = ['clusters', 'silhouette_score', 'davies_bouldin_score',\n",
    "                                      'rand_score', 'adjusted_mutual_info_score', 'mutual_info_score'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 4, figsize = (18, 5))\n",
    "\n",
    "    for i in range(2, 6):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        y_kmeans = kmeans.predict(data)\n",
    "        \n",
    "        i_results = pd.DataFrame({'clusters':[i],\n",
    "                                  'silhouette_score':[silhouette_score(data, y_kmeans)],\n",
    "                                  'davies_bouldin_score':[davies_bouldin_score(data, y_kmeans)],\n",
    "                                  'rand_score':[rand_score(actual_labels, y_kmeans)],\n",
    "                                  'adjusted_mutual_info_score':[adjusted_mutual_info_score(actual_labels, y_kmeans)],\n",
    "                                  'mutual_info_score':[mutual_info_score(actual_labels, y_kmeans)]})\n",
    "        results = pd.concat([results, i_results])\n",
    "\n",
    "        sns.scatterplot(data = reduction, x = 'x', y = 'y',\n",
    "                        hue = y_kmeans, legend = False,\n",
    "                        ax = axs[i-2], palette='viridis')\n",
    "        ax1.set_title(f'{i} clusters')\n",
    "        \n",
    "    \n",
    "    plt.show()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AggClustering(data, reduction, actual_labels):\n",
    "    results = pd.DataFrame(columns = ['clusters', 'linkage', 'silhouette_score', 'davies_bouldin_score',\n",
    "                                     'rand_score', 'adjusted_mutual_info_score', 'mutual_info_score'])\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 4, figsize = (18, 15))\n",
    "    linkage = ['ward', 'complete', 'single']\n",
    "\n",
    "    for j in range(3):\n",
    "        for i in range(2, 6):\n",
    "            aggClus = AgglomerativeClustering(n_clusters = i, linkage = linkage[j])\n",
    "            y_aggClus = aggClus.fit_predict(data)\n",
    "            \n",
    "            i_results = pd.DataFrame({'clusters':[i],\n",
    "                                  'linkage':[linkage[j]],    \n",
    "                                  'silhouette_score':[silhouette_score(data, y_aggClus)],\n",
    "                                  'davies_bouldin_score':[davies_bouldin_score(data, y_aggClus)],\n",
    "                                  'rand_score':[rand_score(actual_labels, y_aggClus)],\n",
    "                                  'adjusted_mutual_info_score':[adjusted_mutual_info_score(actual_labels, y_aggClus)],\n",
    "                                  'mutual_info_score':[mutual_info_score(actual_labels, y_aggClus)]})\n",
    "            results = pd.concat([results, i_results])\n",
    "\n",
    "            sns.scatterplot(data = reduction, x = 'x', y = 'y',\n",
    "                            hue = y_aggClus, legend = False,\n",
    "                            ax = axs[j, i-2], palette='viridis')\n",
    "            axs[j, i-2].set_title(f'{i} clusters, {linkage[j]} linkage')\n",
    "\n",
    "    plt.show()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMMClustering(data, reduction, actual_labels):\n",
    "    results = pd.DataFrame(columns = ['clusters', 'covariance', 'silhouette_score', 'davies_bouldin_score',\n",
    "                                     'rand_score', 'adjusted_mutual_info_score', 'mutual_info_score'])\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 4, figsize = (18, 15))\n",
    "    cov = ['full', 'tied', 'diag']\n",
    "\n",
    "    for j in range(3):\n",
    "        for i in range(2, 6):\n",
    "            gmm = GaussianMixture(n_components=i, covariance_type=cov[j])\n",
    "            y_gmm = gmm.fit_predict(data)\n",
    "            \n",
    "            i_results = pd.DataFrame({'clusters':[i],\n",
    "                                  'covariance':[cov[j]],    \n",
    "                                  'silhouette_score':[silhouette_score(data, y_gmm)],\n",
    "                                  'davies_bouldin_score':[davies_bouldin_score(data, y_gmm)],\n",
    "                                  'rand_score':[rand_score(actual_labels, y_gmm)],\n",
    "                                  'adjusted_mutual_info_score':[adjusted_mutual_info_score(actual_labels, y_gmm)],\n",
    "                                  'mutual_info_score':[mutual_info_score(actual_labels, y_gmm)]})\n",
    "            results = pd.concat([results, i_results])\n",
    "\n",
    "            sns.scatterplot(data = reduction, x = 'x', y = 'y',\n",
    "                            hue = y_gmm, legend = False,\n",
    "                            ax = axs[j, i-2], palette='viridis')\n",
    "            axs[j, i-2].set_title(f'{i} clusters, {cov[j]} covarince')\n",
    "\n",
    "    plt.show()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = KMeansClustering(X_pca45, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = AggClustering(X_pca45, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = GMMClustering(X_pca45, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-reservoir",
   "metadata": {},
   "source": [
    "# TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_csr = csr_matrix(X)\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=50)\n",
    "tsvd.fit(X_csr)\n",
    "X_tsvd_t = tsvd.transform(X_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 8])\n",
    "tSNE = TSNE(random_state=0, verbose=1)\n",
    "X_tsne = tSNE.fit_transform(X_tsvd_t)\n",
    "X_tsne = pd.DataFrame({'x': X_tsne[:, 0], 'y': X_tsne[:, 1], 'label': Y['label'], 'rel' : Y['rel']})\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=[18, 6])\n",
    "sns.scatterplot(data=X_tsne, x='x', y='y', hue='label', ax = ax1)\n",
    "sns.scatterplot(data=X_tsne, x='x', y='y', hue='rel', ax = ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = KMeansClustering(X_tsvd_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = AggClustering(X_tsvd_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = GMMClustering(X_tsvd_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-owner",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_csr = csr_matrix(df_tfidf)\n",
    "nmf = NMF(n_components=8)\n",
    "X_nmf_t = nmf.fit_transform(X_tfidf_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 8])\n",
    "tSNE = TSNE(random_state=0, verbose=1)\n",
    "X_tsne = tSNE.fit_transform(X_nmf_t)\n",
    "X_tsne = pd.DataFrame({'x': X_tsne[:, 0], 'y': X_tsne[:, 1], 'label': Y['label'], 'rel' : Y['rel']})\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=[18, 6])\n",
    "sns.scatterplot(data=X_tsne, x='x', y='y', hue='label', ax = ax1)\n",
    "sns.scatterplot(data=X_tsne, x='x', y='y', hue='rel', ax = ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = KMeansClustering(X_nmf_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = AggClustering(X_nmf_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = GMMClustering(X_nmf_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-syntax",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-thesis",
   "metadata": {},
   "source": [
    "# Sparse PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import SparsePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "spca = SparsePCA(n_components=45)\n",
    "X_spca_t = spca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 8])\n",
    "tSNE = TSNE(random_state=0, verbose=1)\n",
    "X_tsne = tSNE.fit_transform(X_spca_t)\n",
    "X_tsne = pd.DataFrame({'x': X_tsne[:, 0], 'y': X_tsne[:, 1], 'label': Y['label'], 'rel' : Y['rel']})\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=[18, 6])\n",
    "sns.scatterplot(data=X_tsne, x='x', y='y', hue='label', ax = ax1)\n",
    "sns.scatterplot(data=X_tsne, x='x', y='y', hue='rel', ax = ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = KMeansClustering(X_spca_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = AggClustering(X_spca_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = GMMClustering(X_spca_t, X_tsne, Y['rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.reset_index(drop=True).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-suspect",
   "metadata": {},
   "source": [
    "# Najlepsze klastrowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.metrics import calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(data, actual_labels, predict):\n",
    "    return pd.DataFrame({   \n",
    "        'silhouette_score':[silhouette_score(data, predict)],\n",
    "        'davies_bouldin_score':[davies_bouldin_score(data, predict)],\n",
    "        'rand_score':[rand_score(actual_labels, predict)],\n",
    "        'adjusted_mutual_info_score':[adjusted_mutual_info_score(actual_labels, predict)],\n",
    "        'mutual_info_score':[mutual_info_score(actual_labels, predict)],\n",
    "        'calinski_harabasz_score' :[calinski_harabasz_score(data, predict)]\n",
    "    }).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=100,\n",
    "        max_font_size=30,\n",
    "        scale=3,\n",
    "        random_state=1)\n",
    "   \n",
    "    wordcloud=wordcloud.generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-words",
   "metadata": {},
   "source": [
    "### PCA45, 3 klastry, GMM, tied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-muslim",
   "metadata": {},
   "source": [
    "### PCA45, 4 klastry, GMM, tied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components = 4, covariance_type='tied')\n",
    "X_pca45_gmm_4 = gmm.fit_predict(X_pca45)\n",
    "\n",
    "tSNE = TSNE(random_state=0, verbose=1)\n",
    "X_tsne = tSNE.fit_transform(X_pca45)\n",
    "X_tmp = pd.DataFrame({'x': X_tsne[:, 0], 'y': X_tsne[:, 1], 'label': X_pca45_gmm_4})\n",
    "X_tsne = pd.DataFrame({'x': X_tsne[:, 0], 'y': X_tsne[:, 1], 'label': Y['label'], 'rel' : Y['rel']})\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=[18, 6])\n",
    "sns.scatterplot(data = X_tsne, x = 'x', y = 'y', hue = X_pca45_gmm_4, legend = 'auto', palette='viridis', ax = ax1)\n",
    "sns.histplot(X_tmp['label'], ax = ax2, palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_pca45, Y['rel'], X_pca45_gmm_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_tfidf.loc[X_pca45_gmm_4 == 0].sum().sort_values(ascending=False).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_tfidf.loc[X_pca45_gmm_4 == 1].sum().sort_values(ascending=False).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_tfidf.loc[X_pca45_gmm_4 == 2].sum().sort_values(ascending=False).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-credit",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_wordcloud(df_tfidf.loc[X_pca45_gmm_4 == 3].sum().sort_values(ascending=False).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-facility",
   "metadata": {},
   "source": [
    "## TruncatedSVD, 3 klastry, GMM, tied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_csr = csr_matrix(X)\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=50)\n",
    "tsvd.fit(X_csr)\n",
    "X_tsvd_t = tsvd.transform(X_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components = 3, covariance_type='tied')\n",
    "X_tsvd_gmm_3 = gmm.fit_predict(X_tsvd_t)\n",
    "\n",
    "tSNE = TSNE(random_state=0, verbose=1)\n",
    "X_tsne = tSNE.fit_transform(X_tsvd_t)\n",
    "X_tmp = pd.DataFrame({'x': X_tsne[:, 0], 'y': X_tsne[:, 1], 'label': X_tsvd_gmm_3})\n",
    "X_tsne = pd.DataFrame({'x': X_tsne[:, 0], 'y': X_tsne[:, 1], 'label': Y['label'], 'rel' : Y['rel']})\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=[18, 6])\n",
    "sns.scatterplot(data = X_tsne, x = 'x', y = 'y', hue = X_tsvd_gmm_3, legend = 'auto', palette='viridis', ax = ax1)\n",
    "sns.histplot(X_tmp['label'], ax = ax2, palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_tsvd_t, Y['rel'], X_tsvd_gmm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_tfidf.loc[X_tsvd_gmm_3 == 0].sum().sort_values(ascending=False).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_tfidf.loc[X_tsvd_gmm_3 == 1].sum().sort_values(ascending=False).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_tfidf.loc[X_tsvd_gmm_3 == 2].sum().sort_values(ascending=False).to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
